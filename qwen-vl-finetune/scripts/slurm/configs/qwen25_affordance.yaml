# Qwen2.5-VL Pointing Task Training Configuration 
# Model: Qwen2.5-VL-7B with absolute coordinates

# Model configuration
model_name_or_path: "Qwen/Qwen2.5-VL-7B-Instruct"

# Training hyperparameters
learning_rate: 5e-5
per_device_train_batch_size: 16  
gradient_accumulation_steps: 2  
num_train_epochs: 2.0

# Seeds
seed: 42
data_seed: 42

# Dataset configuration - Pointing with absolute coordinates
dataset_use: "epic100_absolute,ego4d_absolute,handal_absolute"

# Training configuration
lora_enable: False
data_flatten: True
tune_mm_vision: True
tune_mm_mlp: True
tune_mm_llm: True
bf16: True

# Image preprocessing - for Qwen2.5-VL
max_pixels: 50176
min_pixels: 784

# Evaluation and saving
eval_strategy: "no"
save_strategy: "steps"
save_steps: 1000  
save_total_limit: 2

# Optimization
weight_decay: 0
warmup_ratio: 0.1
max_grad_norm: 1
lr_scheduler_type: "cosine"
logging_steps: 10

# Model settings
model_max_length: 8192
gradient_checkpointing: True
dataloader_num_workers: 16

# Reporting
report_to: "wandb"
base_run_name: "Qwen25-Affordance-Pointing-7B"
wandb_project: "qwen-affordance-training"
